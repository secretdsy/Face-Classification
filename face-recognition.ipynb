{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "이번 과제의 주제는 \"주어진 인물 사진을 요구사항에 맞게 분류하는 것\" 입니다.  \n",
    "따라서 가장 먼저 각 클래스별로 분포를 파악하는 것이 중요하다고 생각했습니다.  \n",
    "각 클래스는 아래와 같습니다.\n",
    "\n",
    "분류1: 안경쓰지 않은 남자 성인  \n",
    "분류2: 안경쓴 남자 성인  \n",
    "분류3: 남자 아동  \n",
    "분류4: 안경쓰지 않은 여자 성인  \n",
    "분류5: 안경쓴 여자 성인  \n",
    "분류6: 여자 아동  \n",
    "\n",
    "train set의 각 클래스별 개수는 1723, 601, 230, 2568, 374, 354개였고, 각 클래스의 데이터 불균형이 심했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = './label'\n",
    "IMG_PATH = './faces_images'\n",
    "TRAIN_PATH = './data/train'\n",
    "TEST_PATH = './data/test'\n",
    "\n",
    "for i in range(1,7):\n",
    "    os.mkdir(TRAIN_PATH + '/' + str(i) + '/')\n",
    "df_train = pd.read_csv(os.path.join(DATA_PATH, 'train_vision.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DATA_PATH, 'test_vision.csv'))\n",
    "\n",
    "# data augmentation을 염두에 두고 클래스별로 directory를 생성하여 나눴습니다.\n",
    "# train data move\n",
    "for i in range(len(df_train)):\n",
    "    origin_path = os.path.join(IMG_PATH, df_train['filename'][i])\n",
    "    new_path = TRAIN_PATH + '/' + str(df_train['label'][i]) + '/' + df_train['filename'][i]\n",
    "    shutil.move(origin_path, new_path)\n",
    "    \n",
    "# test data move\n",
    "for i in range(len(df_test)):\n",
    "    origin_path = os.path.join(IMG_PATH, df_test['filename'][i])\n",
    "    new_path = os.path.join(TEST_PATH, df_test['filename'][i])\n",
    "    shutil.move(origin_path, new_path)\n",
    "\n",
    "# 각 폴더 개수세기\n",
    "for i in range(1,7):\n",
    "    img_cnt = len(glob.glob1(os.path.join(TRAIN_PATH, str(i)), '*.png'))\n",
    "    print(imag_cnt)\n",
    "\n",
    "# train, validation split\n",
    "data_dir = './data/train/'\n",
    "val_dir = './data/val/'\n",
    "ref = 1\n",
    "dir_len = len(os.listdir(val_dir))\n",
    "\n",
    "if dir_len != 6:\n",
    "    for i in range(1,7):\n",
    "        os.mkdir(val_dir + str(i))\n",
    "\n",
    "for k in range(1,7):\n",
    "    root_dir = os.path.join(data_dir, str(k))\n",
    "    output_dir = os.path.join(val_dir, str(k))\n",
    "    print(len(os.listdir(root_dir)))\n",
    "    print(len(os.listdir(output_dir)))\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        number_of_files = len(os.listdir(root)) \n",
    "        if number_of_files > ref:\n",
    "            ref_copy = int(round(0.2 * number_of_files))\n",
    "            for i in range(ref_copy):\n",
    "                chosen_one = random.choice(os.listdir(root))\n",
    "                file_in_track = root\n",
    "                file_to_copy = file_in_track + '/' + chosen_one\n",
    "                if os.path.isfile(file_to_copy) == True:\n",
    "                    shutil.move(file_to_copy,output_dir)\n",
    "        else:\n",
    "            for i in range(len(files)):\n",
    "                track_list = root\n",
    "                file_in_track = files[i]\n",
    "                file_to_copy = track_list + '/' + file_in_track\n",
    "                if os.path.isfile(file_to_copy) == True:\n",
    "                    shutil.move(file_to_copy,output_dir)\n",
    "    print(len(os.listdir(root_dir)))\n",
    "    print(len(os.listdir(output_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l82IgvMH45TW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "from keras import backend as K\n",
    "warnings.filterwarnings(action='ignore')\n",
    "K.image_data_format()\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, UpSampling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# functional\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate, add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일 경로\n",
    "data_dir = Path('./data/aug')\n",
    "train_dir = data_dir / 'train'\n",
    "val_dir = data_dir / 'val'\n",
    "test_dir = Path('./data')\n",
    "\n",
    "# prediction 파일 경로\n",
    "submit_dir = Path('./submit')\n",
    "\n",
    "# save model 경로\n",
    "save_dir = Path('./savemodel')\n",
    "\n",
    "# csv 파일 경로\n",
    "label_dir = Path('./label')\n",
    "train_path = label_dir / 'train_vision.csv'\n",
    "test_path = label_dir / 'test_vision.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwBMdnLf7xZj"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Generator Parameter\n",
    "    'random_state': 42,\n",
    "    # 좌우 반전\n",
    "    'horizontal_flip': True,\n",
    "    # 회전하는 최대 각도\n",
    "    'rotation_range': 20,\n",
    "    # 좌우로 이동할 최대 비율\n",
    "    'width_shift_range': 0.20,\n",
    "    # 상하로 이동할 최대 비율\n",
    "    'height_shift_range': 0.20,\n",
    "    # 확대 및 축소 최대 비율\n",
    "    'zoom_range': 0.20,\n",
    "    # 밝기 조절 최소, 최대 비율의 범위\n",
    "    'brightness_range': (0.7, 1.3),\n",
    "\n",
    "    # Model Parameter\n",
    "    'img_size': (128, 128),\n",
    "    'input_shape': (128, 128, 3),\n",
    "    'batch_size': 48,\n",
    "    'epochs': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras는 ImageDataGenerator를 사용하여 간편하게 data augmentation 효과를 낼 수 있습니다.\n",
    "\n",
    "baseline을 구축할 때는 사용했지만, data augmentation을 진행한 후로 ImageDataGenerator는 데이터를 불러오는 용도로만 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "whH7ogMx9Xl9",
    "outputId": "9c72cd76-4635-4575-b022-acc0e6674079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29946 images belonging to 6 classes.\n",
      "Found 1171 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "def make_generator(params, train_path, val_path):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input)\n",
    "#         rotation_range=params['rotation_range'],\n",
    "#         width_shift_range=params['width_shift_range'],\n",
    "#         height_shift_range=params['height_shift_range'],\n",
    "#         zoom_range=params['zoom_range'],\n",
    "#         horizontal_flip=params['horizontal_flip'],\n",
    "#         brightness_range=params['brightness_range'])\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=params['img_size'],\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=params['batch_size'],\n",
    "        seed=params['random_state'])\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=params['img_size'],\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle=False)\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "train_generator, validation_generator = make_generator(params, str(train_dir), str(val_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0 :\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else:\n",
    "        return num_samples // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "제가 실험한 방식은 다음과 같습니다.\n",
    "1. 가장 간단한 모델로 baseline을 구축한다.\n",
    "    - 아주 간단함에도 불구하고 public score 기준 81.5점이 나왔습니다.  \n",
    "\n",
    "\n",
    "2. Imagenet 대회에서 좋은 성능을 보인 모델을 사용해본다.\n",
    "    - Xception, ResNet, VGGNet, EfficientNet 등을 사용했습니다.  \n",
    "    - 각각의 모델에 대해서 fine tuning을 진행한 결과 Xception 모델이 가장 높은 점수를 얻을 수 있었습니다.  \n",
    "\n",
    "\n",
    "3. 각 모델의 특징을 파악하고 functional model을 구축한다.\n",
    "    - VGGNet이 feature를 잘 추출하고, ResNet이 residual block 덕분에 분류를 잘한고 생각을 해서  \n",
    "    VGGNet의 Fully Connected Layer 부분에 residual block을 추가하는 functional 모델을 구축했습니다.  \n",
    "    - 결과적으로는 학습이 잘 안돼서 Xception모델과 baseline모델을 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 124, 124, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 58, 58, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 27, 27, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 25, 25, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 23, 23, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              7931904   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 9,133,606\n",
      "Trainable params: 9,133,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### baseline model #####\n",
    "\n",
    "model = None\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=params['input_shape']))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax', kernel_initializer='he_normal'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "U0Hl3-B38PtK",
    "outputId": "7bf9e3d5-bc9b-4943-80c9-9ae3e93d6455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 20,873,774\n",
      "Trainable params: 20,819,246\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##### main model #####\n",
    "\n",
    "cnn_model = Xception(include_top=False, weights=None, input_shape=params['input_shape'])\n",
    "model = Sequential()\n",
    "# imagenet 대회를 위한 모델들은 보통 (220,220) ~ (300,300) 사이의 input size에 최적화 되어있어서\n",
    "# interpolation하여 input size를 (256,256)가 되도록 진행했습니다.\n",
    "# 결과적으로는 interploation을 적용해도 점수 향상에는 도움이 되지 않고, 연산량만 증가하여 이후에는 사용하지 않았습니다.\n",
    "# model.add(UpSampling2D(size=(2,2), input_shape=params['input_shape'], interpolation='bilinear'))\n",
    "model.add(cnn_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(6, activation='softmax', kernel_initializer='he_normal'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 256, 256, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 256, 64) 1792        up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 256, 64) 36928       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 128 147584      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 512)  2359808     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 512)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2048)         1050624     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2048)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          1049088     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2048)         1050624     dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         4196352     dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2048)         0           dense_4[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2048)         4196352     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2048)         4196352     dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2048)         0           add_1[0][0]                      \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2048)         4196352     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2048)         4196352     dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2048)         0           add_2[0][0]                      \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 6)            12294       add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,859,078\n",
      "Trainable params: 38,859,078\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###### functional model ######\n",
    "\n",
    "inputs = Input(shape=(128,128,3))\n",
    "upsam = UpSampling2D(size=(2,2), input_shape=(128,128,3), interpolation='bilinear')(inputs)\n",
    "x1 = Conv2D(64, kernel_size=3, activation='relu', input_shape=(256,256,3), padding='same')(upsam)\n",
    "x1 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(x1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "x2 = Conv2D(128, kernel_size=3, activation='relu', padding='same')(x1)\n",
    "x2 = Conv2D(128, kernel_size=3, activation='relu', padding='same')(x2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "x3 = Conv2D(256, kernel_size=3, activation='relu', padding='same')(x2)\n",
    "x3 = Conv2D(256, kernel_size=3, activation='relu', padding='same')(x3)\n",
    "x3 = Conv2D(256, kernel_size=3, activation='relu', padding='same')(x3)\n",
    "x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "\n",
    "x4 = Conv2D(512, kernel_size=3, activation='relu', padding='same')(x3)\n",
    "x4 = Conv2D(512, kernel_size=3, activation='relu', padding='same')(x4)\n",
    "x4 = Conv2D(512, kernel_size=3, activation='relu', padding='same')(x4)\n",
    "x4 = MaxPooling2D(pool_size=(2, 2))(x4)\n",
    "\n",
    "x5 = Conv2D(512, kernel_size=3, activation='relu', padding='same')(x4)\n",
    "x5 = Conv2D(512, kernel_size=3, activation='relu', padding='same')(x5)\n",
    "x5 = Conv2D(512, kernel_size=3, activation='relu', padding='same')(x5)\n",
    "x6 = MaxPooling2D(pool_size=(2, 2))(x5)\n",
    "\n",
    "x7 = GlobalAveragePooling2D()(x6)\n",
    "\n",
    "fc1 = Dense(2048, activation='relu')(x7)\n",
    "dr = Dropout(0.25)(fc1)\n",
    "fc2 = Dense(512, activation='relu')(dr)\n",
    "dr = Dropout(0.25)(fc2)\n",
    "\n",
    "fc3 = Dense(2048, activation='relu')(fc2)\n",
    "fc4 = Dense(2048, activation='relu')(fc3)\n",
    "add_layer = add([fc1, fc4])\n",
    "\n",
    "fc5 = Dense(2048, activation='relu')(add_layer)\n",
    "fc6 = Dense(2048, activation='relu')(fc5)\n",
    "add_layer2 = add([add_layer, fc6])\n",
    "\n",
    "fc7 = Dense(2048, activation='relu')(add_layer2)\n",
    "fc8 = Dense(2048, activation='relu')(fc7)\n",
    "add_layer3 = add([add_layer2, fc8])\n",
    "outputs = Dense(6, activation='softmax', kernel_initializer='he_normal')(add_layer3)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(),\n",
    "              metrics=['acc'])\n",
    "model.summary()\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "gC7uW3cREacz",
    "outputId": "2094eb38-e28d-4b9a-ea1c-432126787613"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(),\n",
    "#               optimizer=optimizers.Adadelta(),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "4_xMWsmIVQ3p",
    "outputId": "a285dd00-bb38-4e94-9c08-bf7747f29535"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# model을 저장할 때 acc, val_loss, val_acc를 함께 저장할 수 있도록 했습니다.\n",
    "filepath = str(save_dir / 'Xception_adam_ep{epoch:03d}_acc-{acc:.4f}_vloss-{val_loss:.4f}_vacc-{val_acc:.4f}.h5')\n",
    "# 학습을 이어서 진행할 경우 모델을 불러올 수 있습니다.\n",
    "# model = load_model(str(save_dir / 'res152_aug8+real8_val2_ep040_acc-0.9854_vloss-1.7443_vacc-0.9078.h5'))\n",
    "\n",
    "# val_acc를 관찰함으로써 성능이 향상되었을 때만 모델을 저장하도록 할 수 있습니다.\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "# 일정 구간동안 성능이 올라가지 않으면 학습을 조기 종료 시킬 수 있습니다.\n",
    "# earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# callbacks = [checkpoint, earlystop]\n",
    "callbacks = [checkpoint]\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = get_steps(train_generator.samples, params['batch_size']),\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = get_steps(validation_generator.samples, params['batch_size']),\n",
    "    callbacks = callbacks,\n",
    "    # 학습을 이어서 진행할 경우 초기 epoch을 지정할 수 있습니다.\n",
    "    # initial_epoch = 22,\n",
    "    epochs = params['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Make submission  \n",
    "### Model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "mOMi4ZAYEV_d",
    "outputId": "0f64c2c3-a1bd-4184-86ea-4159bcb5877d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 1 classes.\n",
      "42/42 [==============================] - 12s 277ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_filename = 'fix_aug8+real8_val2_ep045_acc-0.9954_vloss-3.3429_vacc-0.9180.h5'\n",
    "model_filepath = str(save_dir / model_filename)\n",
    "csv_filename = model_filename + '.csv'\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    str(test_dir),\n",
    "    classes=['test'],\n",
    "    target_size=params['img_size'],\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=params['batch_size'],\n",
    "    shuffle=False)\n",
    "\n",
    "model = load_model(model_filepath)\n",
    "\n",
    "prediction = model.predict_generator(\n",
    "    generator=test_generator,\n",
    "    steps = get_steps(test_generator.samples, params['batch_size']),\n",
    "    verbose=1)\n",
    "\n",
    "file_name = test_generator.filenames\n",
    "for i in range(len(file_name)):\n",
    "    file_name[i] = file_name[i].split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me1U5LhFem8w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29946 images belonging to 6 classes.\n",
      "Found 1171 images belonging to 6 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction\n",
       "1995          1\n",
       "1996          1\n",
       "1997          5\n",
       "1998          4\n",
       "1999          4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_indices = np.argmax(prediction, axis=1)\n",
    "\n",
    "# Generator class dictionary mapping\n",
    "train_generator, _ = make_generator(params,str(train_dir),str(val_dir))\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v, k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "submission = pd.read_csv(str(test_path))\n",
    "submission = pd.DataFrame(submission)\n",
    "\n",
    "df = pd.DataFrame(file_name, columns=['filename']) \n",
    "df2 = pd.DataFrame(predictions, columns=['prediction'])\n",
    "df['prediction'] = df2\n",
    "\n",
    "submission = pd.merge(submission, df, on=\"filename\")\n",
    "\n",
    "submission = submission[['prediction']]\n",
    "submission.to_csv(str(submit_dir / csv_filename), index=False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "각각의 모델이 실제 클래스를 어떤 클래스로 분류하는지 비교하기 위해서 confusion matrix를 관찰했습니다.  \n",
    "test set에는 label이 없기 때문에 validation set을 통해 비교하였습니다.  \n",
    "결과적으로 남성과 여성을 구별하는 것은 잘 하지만, 남자 아동과 여자 아동을 분류하는 것을 잘 못하고 있는 것을 알게 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1171 images belonging to 6 classes.\n",
      "37/37 [==============================] - 7s 183ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>face_6455.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>face_6245.png</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>face_452.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>face_1334.png</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>face_7020.png</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  label prediction\n",
       "1166  face_6455.png      1          1\n",
       "1167  face_6245.png      4          4\n",
       "1168   face_452.png      1          1\n",
       "1169  face_1334.png      3          3\n",
       "1170  face_7020.png      4          4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filename = 'fix_aug8+real8_val2_ep008_acc-0.9622_vloss-1.1711_vacc-0.9026.h5'\n",
    "model_filepath = str(save_dir / model_filename)\n",
    "csv_filename = model_filename + '.csv'\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    str(val_dir),\n",
    "#     classes=['test'],\n",
    "    target_size=params['img_size'],\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False)\n",
    "\n",
    "model = load_model(model_filepath)\n",
    "\n",
    "train_generator, _ = make_generator(params,str(train_dir),str(val_dir))\n",
    "prediction = model.predict_generator(\n",
    "    generator=test_generator,\n",
    "    steps = get_steps(test_generator.samples, 32),\n",
    "    verbose=1)\n",
    "\n",
    "file_name = test_generator.filenames\n",
    "for i in range(len(file_name)):\n",
    "    file_name[i] = file_name[i][2:]\n",
    "\n",
    "predicted_class_indices = np.argmax(prediction, axis=1)\n",
    "\n",
    "# Generator class dictionary mapping\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v, k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "submission = pd.read_csv(str(train_path))\n",
    "submission = pd.DataFrame(submission)\n",
    "df = pd.DataFrame(file_name, columns=['filename']) \n",
    "df2 = pd.DataFrame(predictions, columns=['prediction'])\n",
    "df['prediction'] = df2\n",
    "submission = pd.merge(submission, df, on=\"filename\")\n",
    "submission = submission.dropna(axis=0)\n",
    "csv_filename = 'prediction' + model_filename + '.csv'\n",
    "submission.to_csv(str(submit_dir / csv_filename), index=False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['label','prediction']]\n",
    "label = submission['label'].values.tolist()\n",
    "prediction = submission['prediction'].values.tolist()\n",
    "\n",
    "for i in range(len(label)):\n",
    "    label[i] = str(label[i])\n",
    "conf_matrix = [[0] * 6 for _ in range(6)]\n",
    "for i in range(len(label)):\n",
    "    conf_matrix[int(label[i])-1][int(prediction[i])-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[327, 1, 2, 15, 0, 0],\n",
       " [0, 119, 0, 0, 1, 0],\n",
       " [1, 0, 42, 0, 0, 3],\n",
       " [2, 0, 2, 502, 1, 7],\n",
       " [0, 0, 0, 0, 75, 0],\n",
       " [0, 0, 3, 2, 0, 66]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation  \n",
    "Data augmentation에 사용한 기법은 아래와 같습니다.\n",
    "1. brightness\n",
    "2. sharpening\n",
    "3. gausian blur\n",
    "4. saturation\n",
    "5. salt\n",
    "6. rotation\n",
    "7. flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "Extension=\".png\"\n",
    "data_dir = Path('./data/aug')\n",
    "raw_dir = data_dir / 'train'\n",
    "aug_dir = data_dir / 'train'\n",
    "dir_list = os.listdir(str(raw_dir))\n",
    "\n",
    "def add_light(image_file):\n",
    "    image=cv2.imread(image_file)\n",
    "    gamma = np.random.randint(7,20) / 10 #(0.7, 2.0)\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    image=cv2.LUT(image, table)\n",
    "    cv2.imwrite(str(Folder_name) + '/' + file_no + str(i) + Extension, image)\n",
    "\n",
    "def sharpen_image(image_file):\n",
    "    image=cv2.imread(image_file)\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    image = cv2.filter2D(image, -1, kernel)\n",
    "    cv2.imwrite(str(Folder_name) + '/' + file_no + str(i) + Extension, image)\n",
    "\n",
    "def gausian_blur(image_file, blur):\n",
    "    image=cv2.imread(image_file)\n",
    "    image = cv2.GaussianBlur(image,(5,5),blur)\n",
    "    cv2.imwrite(str(Folder_name) + '/' + file_no + str(i) + Extension, image)\n",
    "\n",
    "def saturation_image(image_file):\n",
    "    image=cv2.imread(image_file)\n",
    "    saturation = np.random.randint(0, 50)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    v = image[:, :, 2]\n",
    "    v = np.where(v <= 255 - saturation, v + saturation, 255)\n",
    "    image[:, :, 2] = v\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    "    cv2.imwrite(str(Folder_name) + '/' + file_no + str(i) + Extension, image)\n",
    "    \n",
    "def salt_image(image_file):\n",
    "    image=cv2.imread(image_file)\n",
    "    p = 0.5\n",
    "    a = np.random.rand() / 50\n",
    "    noisy = image\n",
    "    num_salt = np.ceil(a * image.size * p)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape]\n",
    "    noisy[coords] = 1\n",
    "    cv2.imwrite(str(Folder_name) + '/' + file_no + str(i) + Extension, image)\n",
    "\n",
    "def rotate_image(image_file):\n",
    "    image=cv2.imread(image_file)\n",
    "    deg = np.random.uniform(-30,30)\n",
    "    rows, cols,c = image.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), deg, 1)\n",
    "    image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    cv2.imwrite(str(Folder_name) + '/' + file_no + str(i) + Extension, image)\n",
    "\n",
    "def flip_image(image_file):\n",
    "    image=cv2.imread(image_file)\n",
    "    dir = 1\n",
    "    image = cv2.flip(image, dir)\n",
    "    cv2.imwrite(str(Folder_name) + '/' + file_no + str(i) + Extension, image)\n",
    "\n",
    "for dirname in dir_list:\n",
    "    LOAD_PATH = raw_dir / dirname\n",
    "    Folder_name = aug_dir / dirname\n",
    "    file_list = os.listdir(str(LOAD_PATH))\n",
    "    # 각 클래스 별로 4400장씩 생성했고, 이를 통해 데이터의 균형을 맞출 수 있었습니다.\n",
    "    cnt = 4400 // len(file_list)\n",
    "    print('dir:', dirname)\n",
    "    for i in range(0, cnt):\n",
    "        print(i)\n",
    "        for filename in file_list:\n",
    "            image_file = str(Folder_name) + '/' + filename\n",
    "            file_no = filename[5:-4] + '_'    \n",
    "            \n",
    "            add_light(image_file)\n",
    "            image_file = str(Folder_name) + '/' + file_no + str(i) + Extension\n",
    "            rotate_image(image_file)\n",
    "            if np.random.rand() < 0.5:\n",
    "                flip_image(image_file)\n",
    "            if np.random.rand() < 0.2:\n",
    "                salt_image(image_file)\n",
    "            if np.random.rand() < 0.3:\n",
    "                blur = np.random.rand()\n",
    "                gausian_blur(image_file, blur)\n",
    "            if np.random.rand() < 0.3:\n",
    "                saturation_image(image_file)\n",
    "            if np.random.rand() < 0.3:\n",
    "                sharpen_image(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority vote\n",
    "ensemble 기법 중에 결과를 기반으로 한 majority vote 방식을 사용했습니다.  \n",
    "각 모델의 prediction을 public score를 기준으로 더했으며, 가장 높은 점수를 얻은 클래스를 택하도록 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['90.25_fix_aug8+real8_val2_ep021_acc-0.9872_vloss-5.8906_vacc-0.9103.h5.csv',\n",
       " '89.5_aug2_ep061_acc-0.9245_vloss-0.0521_vacc-0.9815.csv',\n",
       " '89.5_c7p3sh1z1_adadelta_ep86_vloss-0.452_vacc-0.931.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './bestmodel'\n",
    "file_list = os.listdir(data_dir)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90.25, 89.5, 89.5]\n"
     ]
    }
   ],
   "source": [
    "df_list = [pd.read_csv(os.path.join(data_dir, file), engine='python') for file in file_list]\n",
    "scores = [float(file.split('_')[0]) for file in file_list]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = len(pd.unique(df_list[0]['prediction']))\n",
    "n_class\n",
    "result = []\n",
    "for i in range(df_list[0].shape[0]):\n",
    "    classes = [0] * (n_class + 1)\n",
    "    for j in range(len(df_list)):\n",
    "        classes[df_list[j]['prediction'][i]] += scores[j]\n",
    "    result.append(classes.index(max(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction\n",
       "1995           1\n",
       "1996           1\n",
       "1997           5\n",
       "1998           4\n",
       "1999           4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = df_list[0]\n",
    "submission['prediction'] = result\n",
    "submission.to_csv(os.path.join(data_dir, 'majority_vote.csv'), index=False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "face.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
